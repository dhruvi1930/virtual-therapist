{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3995, 5000, 4830]\n",
      "[467, 700, 653]\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization,AveragePooling2D\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adam,SGD,RMSprop\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import np_utils\n",
    "\n",
    "df=pd.read_csv(r'E:\\demo1\\fer2013.csv')\n",
    "\n",
    "X_train,train_y,X_test,test_y=[],[],[],[]\n",
    "X_test1,test_y1=[],[]\n",
    "#a,h,s=0,0,0\n",
    "h1,h2=0,0\n",
    "for index, row in df.iterrows():\n",
    "    val=row['pixels'].split(\" \")\n",
    "    try:\n",
    "        if 'Training' in row['Usage']:\n",
    "            if (row['emotion']==0):\n",
    "                train_y.append(row['emotion'])\n",
    "                X_train.append(np.array(val,'float32'))#angry\n",
    "            elif (row['emotion']==3):\n",
    "                if(h1<5000):\n",
    "                    train_y.append(1)#happy\n",
    "                    X_train.append(np.array(val,'float32'))\n",
    "                    h1+=1\n",
    "            \n",
    "            elif (row['emotion']==4):\n",
    "                train_y.append(2)#sad\n",
    "                X_train.append(np.array(val,'float32'))\n",
    "            \n",
    "            \n",
    "        elif 'PublicTest' in row['Usage']:\n",
    "            if (row['emotion']==0):\n",
    "                test_y.append(row['emotion'])#angry\n",
    "                X_test.append(np.array(val,'float32'))\n",
    "            elif (row['emotion']==3):\n",
    "                if(h2<700):\n",
    "                    test_y.append(1)#happy\n",
    "                    X_test.append(np.array(val,'float32'))\n",
    "                    h2+=1\n",
    "            elif (row['emotion']==4):\n",
    "                test_y.append(2)#sad\n",
    "                X_test.append(np.array(val,'float32'))\n",
    "    except:\n",
    "        print(f\"error occured at index :{index} and row:{row}\")\n",
    "        \n",
    "j=[0,0,0]\n",
    "for i in train_y:\n",
    "    j[i]+=1\n",
    "print(j)\n",
    "j=[0,0,0]\n",
    "for i in test_y:\n",
    "    j[i]+=1\n",
    "print(j)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 64\n",
    "num_labels = 3\n",
    "batch_size = 64\n",
    "epochs = 100\n",
    "width, height = 48, 48\n",
    "\n",
    "\n",
    "X_train = np.array(X_train,'float32')\n",
    "train_y = np.array(train_y,'float32')\n",
    "X_test = np.array(X_test,'float32')\n",
    "test_y = np.array(test_y,'float32')\n",
    "\n",
    "train_y=np_utils.to_categorical(train_y, num_classes=num_labels)\n",
    "test_y=np_utils.to_categorical(test_y, num_classes=num_labels)\n",
    "\n",
    "#cannot produce\n",
    "#normalizing data between oand 1\n",
    "X_train -= np.mean(X_train, axis=0)\n",
    "X_train /= np.std(X_train, axis=0)\n",
    "\n",
    "X_test -= np.mean(X_test, axis=0)\n",
    "X_test /= np.std(X_test, axis=0)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 48, 48, 1)\n",
    "\n",
    "X_test = X_test.reshape(X_test.shape[0], 48, 48, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 46, 46, 64)        640       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 44, 44, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 20, 20, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 18, 18, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 9, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 9, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 7, 7, 128)         73856     \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 5, 5, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 3075      \n",
      "=================================================================\n",
      "Total params: 1,910,851\n",
      "Trainable params: 1,910,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=(X_train.shape[1:])))\n",
    "model.add(Conv2D(64,kernel_size= (3, 3), activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#2nd convolution layer\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#3rd convolution layer\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "#fully connected neural networks\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(num_labels, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-313f7281e394>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m model.compile(loss=categorical_crossentropy,\n\u001b[0m\u001b[0;32m      2\u001b[0m               \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m               metrics=['accuracy'])\n\u001b[0;32m      4\u001b[0m checkpoint = ModelCheckpoint(r\"E:\\demo1\\ash.h5\", monitor='val_accuracy',save_weights_only=True, mode='max', verbose=1,\n\u001b[0;32m      5\u001b[0m                              save_best_only=True)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.compile(loss=categorical_crossentropy,\n",
    "              optimizer=SGD(lr=0.01),\n",
    "              metrics=['accuracy'])\n",
    "checkpoint = ModelCheckpoint(r\"E:\\demo1\\ash.h5\", monitor='val_accuracy',save_weights_only=True, mode='max', verbose=1,\n",
    "                             save_best_only=True)\n",
    "\n",
    "\n",
    "model.fit(X_train, train_y,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, test_y),\n",
    "          shuffle=True,\n",
    "         callbacks=[checkpoint])\n",
    "\n",
    "fer_json = model.to_json()\n",
    "with open(\"ash.json\", \"w\") as json_file:\n",
    "    json_file.write(fer_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13825 samples, validate on 1820 samples\n",
      "Epoch 1/100\n",
      "13825/13825 [==============================] - 47s 3ms/step - loss: 1.1013 - accuracy: 0.3552 - val_loss: 1.0851 - val_accuracy: 0.3846\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.38462, saving model to E:\\demo1\\n1fer3.h5\n",
      "Epoch 2/100\n",
      "13825/13825 [==============================] - 48s 3ms/step - loss: 1.0949 - accuracy: 0.3664 - val_loss: 1.0918 - val_accuracy: 0.3846\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.38462\n",
      "Epoch 3/100\n",
      "13825/13825 [==============================] - 49s 4ms/step - loss: 1.0952 - accuracy: 0.3520 - val_loss: 1.0886 - val_accuracy: 0.3588\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.38462\n",
      "Epoch 4/100\n",
      "13825/13825 [==============================] - 50s 4ms/step - loss: 1.0951 - accuracy: 0.3601 - val_loss: 1.0876 - val_accuracy: 0.3588\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.38462\n",
      "Epoch 5/100\n",
      "13825/13825 [==============================] - 50s 4ms/step - loss: 1.0952 - accuracy: 0.3588 - val_loss: 1.0896 - val_accuracy: 0.3588\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.38462\n",
      "Epoch 6/100\n",
      "13825/13825 [==============================] - 51s 4ms/step - loss: 1.0951 - accuracy: 0.3541 - val_loss: 1.0964 - val_accuracy: 0.3588\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.38462\n",
      "Epoch 7/100\n",
      "13825/13825 [==============================] - 49s 4ms/step - loss: 1.0951 - accuracy: 0.3625 - val_loss: 1.0848 - val_accuracy: 0.3846\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.38462\n",
      "Epoch 8/100\n",
      "13825/13825 [==============================] - 51s 4ms/step - loss: 1.0950 - accuracy: 0.3593 - val_loss: 1.0927 - val_accuracy: 0.3588\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.38462\n",
      "Epoch 9/100\n",
      "13825/13825 [==============================] - 48s 3ms/step - loss: 1.0955 - accuracy: 0.3557 - val_loss: 1.0884 - val_accuracy: 0.3846\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.38462\n",
      "Epoch 10/100\n",
      "13825/13825 [==============================] - 49s 4ms/step - loss: 1.0951 - accuracy: 0.3617 - val_loss: 1.0898 - val_accuracy: 0.3846\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.38462\n",
      "Epoch 11/100\n",
      "13825/13825 [==============================] - 50s 4ms/step - loss: 1.0952 - accuracy: 0.3591 - val_loss: 1.0891 - val_accuracy: 0.3588\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.38462\n",
      "Epoch 12/100\n",
      "13825/13825 [==============================] - 49s 4ms/step - loss: 1.0951 - accuracy: 0.3614 - val_loss: 1.0866 - val_accuracy: 0.3846\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.38462\n",
      "Epoch 13/100\n",
      "13825/13825 [==============================] - 49s 4ms/step - loss: 1.0950 - accuracy: 0.3637 - val_loss: 1.0859 - val_accuracy: 0.3846\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.38462\n",
      "Epoch 14/100\n",
      "13825/13825 [==============================] - 52s 4ms/step - loss: 1.0951 - accuracy: 0.3573 - val_loss: 1.0873 - val_accuracy: 0.3588\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.38462\n",
      "Epoch 15/100\n",
      "13825/13825 [==============================] - 53s 4ms/step - loss: 1.0956 - accuracy: 0.3514 - val_loss: 1.0870 - val_accuracy: 0.3846\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.38462\n",
      "Epoch 16/100\n",
      "13825/13825 [==============================] - 54s 4ms/step - loss: 1.0954 - accuracy: 0.3571 - val_loss: 1.0849 - val_accuracy: 0.3588\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.38462\n",
      "Epoch 17/100\n",
      "13825/13825 [==============================] - 53s 4ms/step - loss: 1.0951 - accuracy: 0.3581 - val_loss: 1.0876 - val_accuracy: 0.3846\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.38462\n",
      "Epoch 18/100\n",
      "13825/13825 [==============================] - 52s 4ms/step - loss: 1.0953 - accuracy: 0.3586 - val_loss: 1.0871 - val_accuracy: 0.3588\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.38462\n",
      "Epoch 19/100\n",
      "13825/13825 [==============================] - 55s 4ms/step - loss: 1.0956 - accuracy: 0.3507 - val_loss: 1.0863 - val_accuracy: 0.3846\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.38462\n",
      "Epoch 20/100\n",
      "13825/13825 [==============================] - 56s 4ms/step - loss: 1.0950 - accuracy: 0.3583 - val_loss: 1.0916 - val_accuracy: 0.3588\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.38462\n",
      "Epoch 21/100\n",
      "13825/13825 [==============================] - 55s 4ms/step - loss: 1.0953 - accuracy: 0.3549 - val_loss: 1.0887 - val_accuracy: 0.3846\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.38462\n",
      "Epoch 22/100\n",
      "13825/13825 [==============================] - 53s 4ms/step - loss: 1.0947 - accuracy: 0.3582 - val_loss: 1.0857 - val_accuracy: 0.3846\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.38462\n",
      "Epoch 23/100\n",
      "13825/13825 [==============================] - 52s 4ms/step - loss: 1.0951 - accuracy: 0.3594 - val_loss: 1.0892 - val_accuracy: 0.3588  - ETA: 28s - loss: 1. - ETA: 28s - loss: 1.0941 - accura - ETA: 23s - loss:  - ETA: 22s - los - ETA: 0s - loss: 1.0951 \n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.38462\n",
      "Epoch 24/100\n",
      "13825/13825 [==============================] - 54s 4ms/step - loss: 1.0949 - accuracy: 0.3606 - val_loss: 1.0886 - val_accuracy: 0.3588\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.38462\n",
      "Epoch 25/100\n",
      "13825/13825 [==============================] - 51s 4ms/step - loss: 1.0948 - accuracy: 0.3604 - val_loss: 1.0856 - val_accuracy: 0.3846\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.38462\n",
      "Epoch 26/100\n",
      "13825/13825 [==============================] - 53s 4ms/step - loss: 1.0954 - accuracy: 0.3538 - val_loss: 1.0861 - val_accuracy: 0.3846\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.38462\n",
      "Epoch 27/100\n",
      "13825/13825 [==============================] - 52s 4ms/step - loss: 1.0951 - accuracy: 0.3590 - val_loss: 1.0885 - val_accuracy: 0.3846\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.38462\n",
      "Epoch 28/100\n",
      "13825/13825 [==============================] - 51s 4ms/step - loss: 1.0949 - accuracy: 0.3579 - val_loss: 1.0950 - val_accuracy: 0.3588 accura - ETA: \n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.38462\n",
      "Epoch 29/100\n",
      "13825/13825 [==============================] - 52s 4ms/step - loss: 1.0954 - accuracy: 0.3533 - val_loss: 1.0888 - val_accuracy: 0.3846\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.38462\n",
      "Epoch 30/100\n",
      "13825/13825 [==============================] - 51s 4ms/step - loss: 1.0951 - accuracy: 0.3649 - val_loss: 1.0980 - val_accuracy: 0.3588\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.38462\n",
      "Epoch 31/100\n",
      "13825/13825 [==============================] - 52s 4ms/step - loss: 1.0954 - accuracy: 0.3563 - val_loss: 1.0905 - val_accuracy: 0.3588\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.38462\n",
      "Epoch 32/100\n",
      "13825/13825 [==============================] - 49s 4ms/step - loss: 1.0953 - accuracy: 0.3588 - val_loss: 1.0915 - val_accuracy: 0.3846\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.38462\n",
      "Epoch 33/100\n",
      "13825/13825 [==============================] - 52s 4ms/step - loss: 1.0953 - accuracy: 0.3505 - val_loss: 1.0884 - val_accuracy: 0.3846\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.38462\n",
      "Epoch 34/100\n",
      " 8328/13825 [=================>............] - ETA: 19s - loss: 1.0951 - accuracy: 0.3591- ETA: 28s - loss: 1.0955 - accuracy: 0. - ETA: 28s - loss: 1.0"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-460803e8d268>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m           \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m          callbacks=[checkpoint1])\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[0mfer_json1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3727\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3729\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1550\u001b[0m     \"\"\"\n\u001b[1;32m-> 1551\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1552\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1553\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1591\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1593\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "model1 = Sequential()\n",
    "model1.add(Conv2D(32, (3, 3), input_shape=(X_train.shape[1:])))\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model1.add(Conv2D(32, (3, 3)))\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model1.add(Conv2D(64, (3, 3)))\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model1.add(Flatten())\n",
    "model1.add(Dense(64))\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(Dropout(0.5))\n",
    "model1.add(Dense(3))\n",
    "model1.add(Activation('softmax'))\n",
    "\n",
    "opt=RMSprop(learning_rate=0.01)\n",
    "\n",
    "model1.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "checkpoint1 = ModelCheckpoint(r\"E:\\demo1\\n1fer3.h5\", monitor='val_accuracy',save_weights_only=True, mode='max', verbose=1,\n",
    "                             save_best_only=True)\n",
    "\n",
    "\n",
    "model1.fit(X_train, train_y,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, test_y),\n",
    "          shuffle=True,\n",
    "         callbacks=[checkpoint1])\n",
    "\n",
    "fer_json1 = model1.to_json()\n",
    "with open(r\"E:\\demo1\\n1fer3.json\", \"w\") as json_file:\n",
    "    json_file.write(fer_json1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fer_json1 = model1.to_json()\n",
    "with open(r\"E:\\demo1\\n1fer3.json\", \"w\") as json_file:\n",
    "    json_file.write(fer_json1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
